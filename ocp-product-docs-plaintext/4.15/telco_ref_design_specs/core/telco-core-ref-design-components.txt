Telco core reference design components

The following sections describe the various "Red Hat OpenShift Container Platform" components and configurations that you use to configure and deploy clusters to run telco core workloads.
CPU partitioning and performance tuning

New in this release
Open vSwitch (OVS) is removed from CPU partitioning. OVS manages its cpuset dynamically to automatically adapt to network traffic needs. Users no longer need to reserve additional CPUs for handling high network throughput on the primary container network interface (CNI). There is no impact on the configuration needed to benefit from this change.
Description
CPU partitioning allows for the separation of sensitive workloads from generic purposes, auxiliary processes, interrupts, and driver work queues to achieve improved performance and latency. The CPUs allocated to those auxiliary processes are referred to as reserved in the following sections. In hyperthreaded systems, a CPU is one hyperthread.
Limits and requirements

Engineering considerations
Service Mesh

Description
Telco core CNFs typically require a service mesh implementation. The specific features and performance required are dependent on the application. The selection of service mesh implementation and configuration is outside the scope of this documentation. The impact of service mesh on cluster resource utilization and performance, including additional latency introduced into pod networking, must be accounted for in the overall solution engineering.
Networking
"Red Hat OpenShift Container Platform" networking is an ecosystem of features, plugins, and advanced networking capabilities that extend Kubernetes networking with the advanced networking-related features that your cluster needs to manage its network traffic for one or multiple hybrid clusters.

Cluster Network Operator (CNO)

New in this release
Not applicable.
Description
The CNO deploys and manages the cluster network components including the default OVN-Kubernetes network plugin during "Red Hat OpenShift Container Platform" cluster installation. It allows configuring primary interface MTU settings, OVN gateway modes to use node routing tables for pod egress, and additional secondary networks such as MACVLAN.
Limits and requirements

Engineering considerations
Load Balancer

New in this release
Not applicable.
Description
MetalLB is a load-balancer implementation for bare metal Kubernetes clusters using standard routing protocols. It enables a Kubernetes service to get an external IP address which is also added to the host network for the cluster.
Limits and requirements

Engineering considerations
SR-IOV

New in this release
Not applicable
Description
SR-IOV enables physical network interfaces (PFs) to be divided into multiple virtual functions (VFs). VFs can then be assigned to multiple pods to achieve higher throughput performance while keeping the pods isolated. The SR-IOV Network Operator provisions and manages SR-IOV CNI, network device plugin, and other components of the SR-IOV stack.
Limits and requirements

Engineering considerations
NMState Operator

New in this release
Not applicable
Description
The NMState Operator provides a Kubernetes API for performing network configurations across the cluster's nodes. It enables network interface configurations, static IPs and DNS, VLANs, trunks, bonding, static routes, MTU, and enabling promiscuous mode on the secondary interfaces. The cluster nodes periodically report on the state of each node's network interfaces to the API server.
Limits and requirements
Not applicable
Engineering considerations
Logging

New in this release
Not applicable
Description
The ClusterLogging Operator enables collection and shipping of logs off the node for remote archival and analysis. The reference configuration ships audit and infrastructure logs to a remote archive by using Kafka.
Limits and requirements
Not applicable
Engineering considerations
Power Management

New in this release

Description
The Performance Profile can be used to configure a cluster in a high power, low power or mixed (per-pod power management) mode. The choice of power mode depends on the characteristics of the workloads running on the cluster particularly how sensitive they are to latency.
Limits and requirements

Engineering considerations
Storage

Overview
Cloud native storage services can be provided by multiple solutions including OpenShift Data Foundation from Red Hat or third parties.


OpenShift Data Foundation

New in this release
Not applicable
Description
Red Hat OpenShift Data Foundation is a software-defined storage service for containers.
For Telco core clusters, storage support is provided by OpenShift Data Foundation storage services running externally to the application workload cluster. OpenShift Data Foundation supports separation of storage traffic using secondary CNI networks.
Limits and requirements

Engineering considerations
Other Storage
Other storage solutions can be used to provide persistent storage for core clusters. The configuration and integration of these solutions is outside the scope of the telco core RDS. Integration of the storage solution into the core cluster must include correct sizing and performance analysis to ensure the storage meets overall performance and resource utilization requirements.
Monitoring

New in this release
Not applicable
Description
The Cluster Monitoring Operator is included by default on all OpenShift clusters and provides monitoring (metrics, dashboards, and alerting) for the platform components and optionally user projects as well.
Limits and requirements

Engineering considerations
Scheduling

New in this release

Description

Limits and requirements

Engineering considerations
Installation

New in this release
Description
Telco core clusters can be installed using the Agent Based Installer (ABI). This method allows users to install "Red Hat OpenShift Container Platform" on bare metal servers without requiring additional servers or VMs for managing the installation. The ABI installer can be run on any system for example a laptop to generate an ISO installation image. This ISO is used as the installation media for the cluster supervisor nodes. Progress can be monitored using the ABI tool from any system with network connectivity to the supervisor nodeâ€™s API interfaces.
Limits and requirements

Engineering considerations
Security

New in this release

Description
Telco operators are security conscious and require clusters to be hardened against multiple attack vectors. Within "Red Hat OpenShift Container Platform", there is no single component or feature responsible for securing a cluster. This section provides details of security-oriented features and configuration for the use models covered in this specification.
Limits and requirements

Engineering considerations
Scalability

New in this release
Not applicable
Description
Clusters will scale to the sizing listed in the limits and requirements section.
Limits and requirements

Engineering considerations
Not applicable
Additional configuration
Disconnected environment

Description
Telco core clusters are expected to be installed in networks without direct access to the internet. All container images needed to install, configure, and operator the cluster must be available in a disconnected registry. This includes "Red Hat OpenShift Container Platform" images, day-2 Operator Lifecycle Manager (OLM) Operator images, and application workload images. The use of a disconnected environment provides multiple benefits, for example:
Limits and requirements

Engineering considerations
Not applicable
Kernel

New in this release
Not applicable
Description
The user can install the following kernel modules by using MachineConfig to provide extended kernel functionality to CNFs:
Limits and requirements

Engineering considerations
Not applicable